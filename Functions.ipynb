{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning criminal data\n",
    "def crime_cleaner(data):\n",
    "    # Merge key with crime db to gain state / city names\n",
    "    washing = data.merge(key00,left_on=['FIPS_CTY','FIPS_ST'], right_on=['County FIPS Code','State FIPS Code'])\n",
    "    # Rearrange columns\n",
    "    washing = washing[['STUDYNO','EDITION','PART','IDNO','year','FIPS_ST','State FIPS Code','State Abbreviation','FIPS_CTY','County FIPS Code','GU Name','CPOPARST','AG_ARRST','JURFLAG','COVIND', 'GRNDTOT','P1TOT','P1VLNT','P1PRPTY','MURDER','RAPE','ROBBERY','AGASSLT','BURGLRY','LARCENY','MVTHEFT','ARSON','OTHASLT','FRGYCNT','FRAUD','EMBEZL','STLNPRP','VANDLSM','WEAPONS','COMVICE','SEXOFF','DRUGTOT','DRGSALE','COCSALE','MJSALE','SYNSALE','OTHSALE','DRGPOSS','COCPOSS','MJPOSS','SYNPOSS','OTHPOSS','GAMBLE','BOOKMKG','NUMBERS','OTGAMBL','OFAGFAM','DUI','LIQUOR','DRUNK','DISORDR','VAGRANT','ALLOTHR','SUSPICN','CURFEW','RUNAWAY']]\n",
    "    \n",
    "    # Select only wanted columns\n",
    "    clean = washing[['year','State Abbreviation','GU Name','MURDER','P1TOT','P1VLNT','P1PRPTY','RAPE','ROBBERY','AGASSLT','BURGLRY','LARCENY','MVTHEFT','ARSON','OTHASLT','FRGYCNT','FRAUD','EMBEZL','STLNPRP','VANDLSM','WEAPONS','COMVICE','SEXOFF','DRUGTOT','DRGSALE','COCSALE','MJSALE','SYNSALE','OTHSALE','DRGPOSS','COCPOSS','MJPOSS','SYNPOSS','OTHPOSS','GAMBLE','BOOKMKG','NUMBERS','OTGAMBL','OFAGFAM','DUI','LIQUOR','DRUNK','DISORDR','VAGRANT','ALLOTHR','SUSPICN','CURFEW','RUNAWAY']]\n",
    "    return clean\n",
    "# Function for cleaning economic data\n",
    "def wage_cleaner(data):\n",
    "        # Drop Unwanted columns\n",
    "    base = data.drop(['Area\\nCode','Own','NAICS','Qtr','Status Code'],axis=1)\n",
    "    # Select County level data\n",
    "    washing = base.loc[(base['Area Type'] == 'County')]\n",
    "    washing['Cnty'] = washing['Cnty'].astype('int64') # Convert to int for merging // Throws error\n",
    "    washing['St'] = washing['St'].astype('int64')    # Convert to into for merging // Throws error\n",
    "    # Merge with key\n",
    "    washing = washing.merge(key00,left_on=['St','Cnty'], right_on=['State FIPS Code','County FIPS Code'])\n",
    "    # Rearrange columns and drop unwanted columns\n",
    "    county_wages = washing[['State Abbreviation','GU Name', 'Year', 'Area Type', 'St Name', 'Area', 'Ownership','Industry', 'Establishment Count', 'July Employment','August Employment', 'September Employment', 'Total Quarterly Wages','Average Weekly Wage', 'Employment Location Quotient Relative to U.S.','Total Wage Location Quotient Relative to U.S.']]\n",
    "    county_wages['Establishment Count'] = county_wages['Establishment Count'].str.replace(',','')  # Get rid of comma // Throws Error\n",
    "    county_wages['Establishment Count'] = pd.to_numeric(county_wages['Establishment Count'])   # Convert to interger // Throws Error\n",
    "    county_wages['September Employment'] = county_wages['September Employment'].str.replace(',','')  # Get rid of comma // Throws Error\n",
    "    county_wages['September Employment'] = pd.to_numeric(county_wages['September Employment'])    # Convert to interger // Throws Error  \n",
    "    county_wages['Average Weekly Wage'] = county_wages['Average Weekly Wage'].str.replace(',','')  # Get rid of comma // Throws Error\n",
    "    county_wages['Average Weekly Wage'] = pd.to_numeric(county_wages['Average Weekly Wage'])  # Convert to interger // Throws Error\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('0','') # Formatting to fix year 2018 industry codes\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('1','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('2','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('3','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('4','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('5','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('6','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('7','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('8','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('9','')\n",
    "    \n",
    "#     state_wages = base.loc[(base['Area Type'] == 'State')]   # State Level Wages\n",
    "#     nation_wages = base.loc[(base['Area Type'] == 'Nation')]    # Nation Level Data\n",
    "#     urban_wages = base.loc[(base['Area Type'] == 'MSA')]   # Metropolitan Level Data\n",
    "    return county_wages #,state_wages,nation_wages,urban_wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull and reformat target stats for target industries\n",
    "def test_func(new_world,keys,s,n):\n",
    "    bin = []\n",
    "    x = new_world.loc[new_world['Industry'] == n]\n",
    "    x = x[s].tolist()\n",
    "    for a in x:\n",
    "        bin.append(a)\n",
    "    return bin\n",
    "\n",
    "# Select largest industries\n",
    "def big_industry_bot(samp_db):\n",
    "        # Select most common industries from sample\n",
    "    trash = []\n",
    "    industry_all = []  # List of all unique industries in sample\n",
    "    for a in keys:\n",
    "        for b in samp_db[a]['Industry']:\n",
    "            trash.append(b)\n",
    "    for a in trash:\n",
    "        if a not in industry_all:\n",
    "            industry_all.append(a)\n",
    "    base_dic = {}\n",
    "    for a in industry_all:\n",
    "        base_dic[a] = [trash.count(a)]\n",
    "\n",
    "    base99 = pd.DataFrame(data=base_dic)\n",
    "    base99 = base99.transpose()\n",
    "    base99 = base99.nlargest(6,0)\n",
    "    base99 = base99.transpose()\n",
    "    industry = base99.columns.tolist()\n",
    "    industry = industry[1:] # Remove 'all industries' from count\n",
    "    return industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Called from bot 97\n",
    "def bot99(data):\n",
    "    x = data.dtypes\n",
    "    x = pd.DataFrame(data=x)\n",
    "    x = x.transpose()\n",
    "    # Create list of column names that are not int64\n",
    "    target = []\n",
    "    for a in x:\n",
    "        if x[a][0] == 'object':\n",
    "            b = str(x[a])[:-15]\n",
    "            b = b[18:]\n",
    "            target.append(b)\n",
    "    # Convert string columns to interger columns\n",
    "    for a in target:\n",
    "        data[a] = data[a].str.replace(',','')\n",
    "        data[a] = data[a].astype(float)\n",
    "    return data\n",
    "def polishing(data,industry):\n",
    "    counties_with_corrupted_data = []\n",
    "    print('\\n\\nData is asymmetrical, searching for and dropping uneven data...')\n",
    "    # Pull each county in sample\n",
    "    for i in keys:\n",
    "        searching = data.loc[(data['State Abbreviation'] == i[:2])&(data['GU Name'] == i[4:])]\n",
    "        container = []\n",
    "        # Create container of all instances of industry for county\n",
    "        for n in searching['Industry']:\n",
    "            container.append(n)\n",
    "        # Count number of instances for each industry\n",
    "        for a in industry:\n",
    "            counter = container.count(a)\n",
    "            # If there are not 5 years of data present for the industry, store key(state & county) in list\n",
    "            if counter != 5:\n",
    "                counties_with_corrupted_data.append(i)\n",
    "    counties_with_corrupted_data = np.unique(counties_with_corrupted_data).tolist() # get rid of duplicates     \n",
    "    print('Counties with corrupted data: ',counties_with_corrupted_data,'\\n\\n')\n",
    "    for i in counties_with_corrupted_data:\n",
    "        data = data.drop(data[(data['State Abbreviation']==i[:2])&(data['GU Name']==i[4:])].index)\n",
    "    return data\n",
    "    \n",
    "# Bot to check that all columns in data frame are symmetrical \n",
    "def bot98(data,industry): \n",
    "    # Create a list of all industry data entrys\n",
    "    l1 = []\n",
    "    for a in data['Industry']:\n",
    "        l1.append(a)\n",
    "    print('Count of target industries in sample \\n\\n MUST ALL BE SAME\\n')\n",
    "    # Find count of each indutry in sample\n",
    "    l2 = []\n",
    "    for a in industry:\n",
    "        #print(a,'//',l1.count(a)) # Print out count of each industry in data frame\n",
    "        l2.append(l1.count(a))\n",
    "\n",
    "    c = max(l2)\n",
    "    failed_check_counts = 0\n",
    "    for a in l2:\n",
    "        if a == c:\n",
    "            print('Check')\n",
    "        else:\n",
    "            print('Failed Industry Count Check')\n",
    "            failed_check_counts += 1\n",
    "    # If a county has less than 5 instances of an industry, will be removed\n",
    "    if failed_check_counts > 0:\n",
    "        make_it_symmy = polishing(data,industry)\n",
    "        return make_it_symmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot97(data):\n",
    "    data_a = bot99(data[y])\n",
    "    return pd.concat([data[z[:8]],data_a],1)\n",
    "# Merging databases Together\n",
    "def bot96(edata,cdata,cols):\n",
    "    db_a = cdata.merge(edata,left_on=['State Abbreviation','GU Name'],right_on=['State Abbreviation','GU Name'])\n",
    "    return db_a[cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
