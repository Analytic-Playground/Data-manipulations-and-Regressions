{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMSE Project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random as random\n",
    "import statsmodels.api as sm\n",
    "from linearmodels import PanelOLS\n",
    "from linearmodels import RandomEffects\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 crime: (3177, 56) // key: (41787, 7)\n",
      "2019 Housing: (1921, 17)\n",
      "2018 Wages: (62724, 21)\n",
      "7313843 unique datapoints in all datasets\n"
     ]
    }
   ],
   "source": [
    "# Reading in Data\n",
    "# Keys to extract formatted State and County names\n",
    "key = pd.read_excel('fips_codes_website.xls')   # Counties and major cities\n",
    "key00 = pd.read_csv('FIPS_countycodes.txt',delimiter=',')  # Counties only\n",
    "key00['GU Name'] = key00['GU Name'].str[:-7]  # Slice 'county' from names\n",
    "# Housing Data\n",
    "zillow2019 = pd.read_excel(\"County_Zhvi_Summary_AllHomes2019.xls\")\n",
    "zillow2019['RegionName'] = zillow2019['RegionName'].str[:-7]  # Slice 'county' from names\n",
    "# Crime\n",
    "crime2010 = pd.read_csv('33523-0001-crimedata2010.txt',delimiter='\\t')\n",
    "crime2012 = pd.read_csv('35019-0001-crimedata2012.txt',delimiter='\\t')\n",
    "crime2014 = pd.read_csv('36399-0001-crimedata2014.txt',delimiter='\\t')\n",
    "crime2016 = pd.read_csv('37059-0001-crimedata2016.txt',delimiter='\\t')\n",
    "# Enumployment & Wages\n",
    "#test_wages_18 = pd.read_excel('allhlcn183.xlsx',sheet_name='US_St_Cn_MSA')\n",
    "wage_unemp2018 = pd.read_csv('allhlcn183wage_unemp2018.txt',delimiter='\\t',dtype={'St':str})\n",
    "wage_unemp2016 = pd.read_csv('allhlcn163wage_unemp2016.txt',delimiter='\\t',dtype={'St':str})\n",
    "wage_unemp2014 = pd.read_csv('allhlcn143wage_unemp2014.txt',delimiter='\\t',dtype={'St':str})\n",
    "wage_unemp2012 = pd.read_csv('allhlcn123wage_unemp2012.txt',delimiter='\\t',dtype={'St':str})\n",
    "wage_unemp2010 = pd.read_csv('allhlcn103wage_unemp2010.txt',delimiter='\\t',dtype={'St':str})\n",
    "\n",
    "print(\"2014 crime:\",crime2014.shape,\"// key:\",key.shape)\n",
    "print(\"2019 Housing:\",zillow2019.shape)\n",
    "print('2018 Wages:',wage_unemp2018.shape)\n",
    "x = ((crime2014.shape[0])*(crime2014.shape[1]))*4 + ((wage_unemp2018.shape[0])*(wage_unemp2018.shape[1]))*5 + (key00.shape[0])*key00.shape[1]\n",
    "print(x,'unique datapoints in all datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[i[i.find(' ')+1:] for i in test_wages_18['Industry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crime_cleaner(data):\n",
    "    # Merge key with crime db to gain state / city names\n",
    "    washing = data.merge(key00,left_on=['FIPS_CTY','FIPS_ST'], right_on=['County FIPS Code','State FIPS Code'])\n",
    "    # Rearrange columns\n",
    "    # for 'key'\n",
    "    #washing = washing[['STUDYNO','EDITION','PART','IDNO','FIPS_ST','State FIPS Code','State Abbreviation','FIPS_CTY','County FIPS Code','GU Name','Entity Description','CPOPARST','AG_ARRST','JURFLAG','COVIND', 'GRNDTOT','P1TOT','P1VLNT','P1PRPTY','MURDER','RAPE','ROBBERY','AGASSLT','BURGLRY','LARCENY','MVTHEFT','ARSON','OTHASLT','FRGYCNT','FRAUD','EMBEZL','STLNPRP','VANDLSM','WEAPONS','COMVICE','SEXOFF','DRUGTOT','DRGSALE','COCSALE','MJSALE','SYNSALE','OTHSALE','DRGPOSS','COCPOSS','MJPOSS','SYNPOSS','OTHPOSS','GAMBLE','BOOKMKG','NUMBERS','OTGAMBL','OFAGFAM','DUI','LIQUOR','DRUNK','DISORDR','VAGRANT','ALLOTHR','SUSPICN','CURFEW','RUNAWAY','FIPS Entity Code','ANSI Code']]\n",
    "    # for 'key00'\n",
    "    washing = washing[['STUDYNO','EDITION','PART','IDNO','FIPS_ST','State FIPS Code','State Abbreviation','FIPS_CTY','County FIPS Code','GU Name','CPOPARST','AG_ARRST','JURFLAG','COVIND', 'GRNDTOT','P1TOT','P1VLNT','P1PRPTY','MURDER','RAPE','ROBBERY','AGASSLT','BURGLRY','LARCENY','MVTHEFT','ARSON','OTHASLT','FRGYCNT','FRAUD','EMBEZL','STLNPRP','VANDLSM','WEAPONS','COMVICE','SEXOFF','DRUGTOT','DRGSALE','COCSALE','MJSALE','SYNSALE','OTHSALE','DRGPOSS','COCPOSS','MJPOSS','SYNPOSS','OTHPOSS','GAMBLE','BOOKMKG','NUMBERS','OTGAMBL','OFAGFAM','DUI','LIQUOR','DRUNK','DISORDR','VAGRANT','ALLOTHR','SUSPICN','CURFEW','RUNAWAY']]\n",
    "    \n",
    "    # Select only wanted columns\n",
    "    clean = washing[['State Abbreviation','GU Name','MURDER','P1TOT','P1VLNT','P1PRPTY','RAPE','ROBBERY','AGASSLT','BURGLRY','LARCENY','MVTHEFT','ARSON','OTHASLT','FRGYCNT','FRAUD','EMBEZL','STLNPRP','VANDLSM','WEAPONS','COMVICE','SEXOFF','DRUGTOT','DRGSALE','COCSALE','MJSALE','SYNSALE','OTHSALE','DRGPOSS','COCPOSS','MJPOSS','SYNPOSS','OTHPOSS','GAMBLE','BOOKMKG','NUMBERS','OTGAMBL','OFAGFAM','DUI','LIQUOR','DRUNK','DISORDR','VAGRANT','ALLOTHR','SUSPICN','CURFEW','RUNAWAY']]\n",
    "    return clean\n",
    "def wage_cleaner(data):\n",
    "    # Drop Unwanted columns\n",
    "    base = data.drop(['Area\\nCode','Own','NAICS','Qtr','Status Code'],axis=1)\n",
    "    # Select County level data\n",
    "    washing = base.loc[(base['Area Type'] == 'County')]\n",
    "    washing['Cnty'] = washing['Cnty'].astype('int64') # Convert to int for merging // Throws error\n",
    "    washing['St'] = washing['St'].astype('int64')    # Convert to into for merging // Throws error\n",
    "    # Merge with key\n",
    "    washing = washing.merge(key00,left_on=['St','Cnty'], right_on=['State FIPS Code','County FIPS Code'])\n",
    "    # Rearrange columns and drop unwanted columns\n",
    "    county_wages = washing[['State Abbreviation','GU Name', 'Year', 'Area Type', 'St Name', 'Area', 'Ownership','Industry', 'Establishment Count', 'July Employment','August Employment', 'September Employment', 'Total Quarterly Wages','Average Weekly Wage', 'Employment Location Quotient Relative to U.S.','Total Wage Location Quotient Relative to U.S.']]\n",
    "    county_wages['Establishment Count'] = county_wages['Establishment Count'].str.replace(',','')  # Get rid of comma // Throws Error\n",
    "    county_wages['Establishment Count'] = pd.to_numeric(county_wages['Establishment Count'])   # Convert to interger // Throws Error\n",
    "    county_wages['September Employment'] = county_wages['September Employment'].str.replace(',','')  # Get rid of comma // Throws Error\n",
    "    county_wages['September Employment'] = pd.to_numeric(county_wages['September Employment'])    # Convert to interger // Throws Error  \n",
    "    county_wages['Average Weekly Wage'] = county_wages['Average Weekly Wage'].str.replace(',','')  # Get rid of comma // Throws Error\n",
    "    county_wages['Average Weekly Wage'] = pd.to_numeric(county_wages['Average Weekly Wage'])  # Convert to interger // Throws Error\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('0','') # Formatting to fix year 2018 industry codes\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('1','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('2','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('3','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('4','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('5','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('6','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('7','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('8','')\n",
    "    county_wages['Industry'] = county_wages['Industry'].str.replace('9','')\n",
    "    \n",
    "    state_wages = base.loc[(base['Area Type'] == 'State')]   # State Level Wages\n",
    "    nation_wages = base.loc[(base['Area Type'] == 'Nation')]    # Nation Level Data\n",
    "    urban_wages = base.loc[(base['Area Type'] == 'MSA')]   # Metropolitan Level Data\n",
    "    return county_wages,state_wages,nation_wages,urban_wages\n",
    "\n",
    "def search(county,state):\n",
    "    # Collect crime data from all years\n",
    "    crime1 = crime10.loc[(crime10['GU Name'] == county) & (crime10['State Abbreviation'] == state)]\n",
    "    crime2 = crime12.loc[(crime12['GU Name'] == county) & (crime12['State Abbreviation'] == state)]\n",
    "    crime3 = crime14.loc[(crime14['GU Name'] == county) & (crime14['State Abbreviation'] == state)]\n",
    "    crime4 = crime16.loc[(crime16['GU Name'] == county) & (crime16['State Abbreviation'] == state)]\n",
    "    crime = crime1,crime2,crime3,crime4\n",
    "    # Collect wage and firm data from all years :: wage[0] pulls county level data, change to pull state, national, or urban levels\n",
    "    wage1 = wage10[0].loc[(wage10[0]['GU Name'] == county) & (wage10[0]['State Abbreviation'] == state)]\n",
    "    wage2 = wage12[0].loc[(wage12[0]['GU Name'] == county) & (wage12[0]['State Abbreviation'] == state)]\n",
    "    wage3 = wage14[0].loc[(wage14[0]['GU Name'] == county) & (wage14[0]['State Abbreviation'] == state)]\n",
    "    wage4 = wage16[0].loc[(wage16[0]['GU Name'] == county) & (wage16[0]['State Abbreviation'] == state)]\n",
    "    wage5 = wage18[0].loc[(wage18[0]['GU Name'] == county) & (wage18[0]['State Abbreviation'] == state)]\n",
    "    wages = wage1,wage2,wage3,wage4,wage5\n",
    "    return {'Crime':crime,'Industry':wages}\n",
    "\n",
    "# Yearly cleaned databases\n",
    "crime10 = crime_cleaner(crime2010)\n",
    "crime12 = crime_cleaner(crime2012)\n",
    "crime14 = crime_cleaner(crime2014)\n",
    "crime16 = crime_cleaner(crime2016)\n",
    "cols = list(crime14.columns.values) # Grab columns\n",
    "# Cleaned Wage Data\n",
    "wage10 = wage_cleaner(wage_unemp2010) # Returns 3 items; county, state, national, and urban level data sets\n",
    "wage12 = wage_cleaner(wage_unemp2012)\n",
    "wage14 = wage_cleaner(wage_unemp2014)\n",
    "wage16 = wage_cleaner(wage_unemp2016)\n",
    "wage18 = wage_cleaner(wage_unemp2018)\n",
    "\n",
    "#wage18[0]['Industry'] = [i[i.find(' ')+1:] for i in wage18[0]['Industry']] # Get to work\n",
    "wage18[0]['Industry'] = wage18[0]['Industry'].str[1:] # Remove first space in 2018 industry codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide half of data for analysis / statistical learning\n",
    "# Generate Random Index values\n",
    "dbindex = []\n",
    "for i in range(int(len(crime2010['FIPS_CTY'])/2)):\n",
    "               r = random.randint(0,len(crime2010['FIPS_CTY']))\n",
    "               dbindex.append(r)\n",
    "hidden_data = pd.DataFrame.empty\n",
    "testing_data = pd.DataFrame.empty\n",
    "\n",
    "# Generate Sample of Randomly Selected Counties\n",
    "n = 5 # Numer of random samples\n",
    "print(\"Randomly Generated Cities:\\nState County\")\n",
    "for i in range(n):\n",
    "    r = random.randint(0,len(crime12))\n",
    "    print(crime12['State Abbreviation'].iloc[r]+', '+crime12['GU Name'].iloc[r])\n",
    "#print(dbindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S E A R C H #\n",
    "##############\n",
    "print(\"IF USING 'KEY00', COUNTIES ONLY\")\n",
    "CountCit = input(\"Enter a county: \")\n",
    "state = input(\"Enter a state abbreviation: \")\n",
    "\n",
    "# Search indexing || Crime data 2010-2016, Wages 2010-2018,\n",
    "collect = search(CountCit,state)\n",
    "# Indexing of 'Collect' :: [crime / wages][data by year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects 10 Random counties and stores them as a dictionary by count // Key = MI, County\n",
    "samp_db = {}\n",
    "for n in range(10):\n",
    "    r = random.randint(0,len(crime12))\n",
    "    x = crime12['State Abbreviation'].iloc[r] # Pull State Abreviation\n",
    "    y = crime12['GU Name'].iloc[r]  # Pull analogous county name\n",
    "    z = x+', '+y # Format name for dictionary key\n",
    "    agg = search(y,x) # Return criminal and economic data\n",
    "    samp_db[z] = agg  # Add data to empty dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samp_db.keys())\n",
    "\n",
    "agg_crimes = []  # List of crime coutns for all counties in sample database\n",
    "for n in samp_db:  # For each county in sample\n",
    "    for i in crimes:  # For each crime in that county\n",
    "        tsearch = i\n",
    "        agg_crimes.append(searchcrime_cleaner(samp_db[n],crimes,tsearch))  # Pull data\n",
    "     \n",
    "# Combined into list-> database\n",
    "#test_dic = {}\n",
    "# for i in samp_db:\n",
    "#     for n in industry:\n",
    "#         test_dic[i+\" wages\"] = wage_dic[i][:-1]\n",
    "#         test_dic[i+\" jobs\"] = emp_dic[i][:-1]\n",
    "print(\"Crimes\",crimes)\n",
    "print(\"            CNTY01 // DRGPOSS //             AGASSLT //            DUI\")\n",
    "print(\"Aggregate Crimes: \",agg_crimes)\n",
    "print(\"Collect: \",collect['Crime'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Multiple Regression Testing\n",
    "# multireg_dic = {}    \n",
    "# for i in wage_dic:  # For each industry in the wage dictionary\n",
    "#     multireg_dic[i+\" wages\"] = wage_dic[i][:-1] # Add wage data to new dictionary, retitle for calraification\n",
    "#     multireg_dic[i+\" jobs\"] = emp_dic[i][:-1]  # Add employment numbers per industry, retitle for calarification\n",
    "# # Now we have employment and wage data in a single dictionary    \n",
    "\n",
    "# multireg = pd.DataFrame(data=multireg_dic)  # Convert dictionary into a dataframe\n",
    "# x = multireg[list(multireg.columns.values)[:3]]  # Use only the first 3 columns to regress\n",
    "# y = crime_dic['DUI']  # Set y variable\n",
    "\n",
    "# model = sm.OLS(y, x).fit()\n",
    "# predictions = model.predict(x) # make the predictions by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrest Options\n",
    "collect['Crime'][0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Plotting & Collecting Specific Data\n",
    "crimes = 'DRGPOSS','AGASSLT','DUI'\n",
    "def searchcrime_cleaner(data,crimes,tsearch):\n",
    "    container = []\n",
    "    count = 0\n",
    "    for i in range(len(data['Crime'])):\n",
    "        knight = data['Crime'][count][tsearch].values\n",
    "        container.append(knight)\n",
    "        count += 1\n",
    "    container = container[0][0],container[1][0],container[2][0],container[3][0]\n",
    "    return container\n",
    "# Pull cleaned crime data, store in dictionary\n",
    "crime_dic = {}\n",
    "for i in crimes:\n",
    "    tsearch = i\n",
    "    crime_dic[i] = searchcrime_cleaner(collect,crimes,tsearch)\n",
    "\n",
    "\n",
    "name = collect['Crime'][0]['GU Name'].values, collect['Crime'][0]['State Abbreviation'].values\n",
    "name = name[0]+\" County, \"+name[1]\n",
    "years = (2010,2012,2014,2016)\n",
    "#Plotting\n",
    "for i in crime_dic:\n",
    "    plt.plot(years,crime_dic[i],label=i)\n",
    "    plt.suptitle(\"Plot of Crime\",size=16)\n",
    "    plt.title(name[0], size=12)\n",
    "    plt.xlabel(\"Years\")\n",
    "    plt.ylabel(\"Number of Arrests\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "#plt.savefig('name')\n",
    "houdata = zillow2019.loc[(zillow2019['RegionName'].values == CountCit) & (zillow2019['State'].values == state)]\n",
    "try:\n",
    "    print(\"Average house price, 2019:  $\",int(houdata['Zhvi']))\n",
    "    print(\"Metro areas:\",houdata['Metro'].values[0])\n",
    "except:\n",
    "    print('--No Housing Data Available For This County--')\n",
    "print(crime_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graphics for Industry and economic Data\n",
    "collect['Industry'][0].columns    # Statistic options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning data from search variable\n",
    "def search_industrydata_cleaner(data,stat,tsearch):\n",
    "    container = []\n",
    "    count = 0\n",
    "    for n in range(len(data['Industry'])):    # Loop for pulling data of multiple years      \n",
    "        container.append(data['Industry'][n].loc[(data['Industry'][n]['Industry']==tsearch)][stat].values)\n",
    "#                          dictionary//year       dictionary//year//column    comparison/DATA TO PULL\n",
    "        count += 1\n",
    "    container = container[0][0],container[1][0],container[2][0],container[3][0],container[4][0]\n",
    "    return container # Return a list of individual values\n",
    "\n",
    "# Function to find largest industries per county\n",
    "def most_establishments(data):\n",
    "    data = data.loc[(data['Industry'] != '10 Total, all industries')] # Remove Totals, 2018\n",
    "    data = data.loc[(data['Industry'] != 'Total, all industries')] # Remove Totals, all other years\n",
    "    data = data.nlargest(4,'Establishment Count')\n",
    "    return data\n",
    "\n",
    "industry = most_establishments(collect['Industry'][4])  # Returns 4 largest industries in 2018 ,index = 4\n",
    "industrydata = industry # Data set for other metrics in largest industries\n",
    "industry = list(industry['Industry']) # List of largest industries for reference purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stat = 'Establishment Count'  \n",
    "# Statistic associated with industry:: Establishment Count,Average Weekly Wage,September Employment\n",
    "indus_dic = {}\n",
    "for i in industry:\n",
    "    tsearch = i\n",
    "    rook = search_industrydata_cleaner(collect,stat,tsearch)\n",
    "    indus_dic[i] = rook\n",
    "# Plotting Searched Data\n",
    "name = collect['Industry'][0]['GU Name'].values,collect['Industry'][0]['State Abbreviation'].values\n",
    "name = name[0][0]+\" County, \"+name[1][0]\n",
    "years = 2010,2012,2014,2016,2018\n",
    "for i in industry:\n",
    "    plt.plot(years,indus_dic[i],label=i)\n",
    "    plt.suptitle('Number of Establishments per 4 Biggest Industries')\n",
    "    plt.title(name)\n",
    "    plt.legend()\n",
    "plt.grid()\n",
    "#plt.savefig('name')\n",
    "indus_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Employment numbers\n",
    "stat = 'September Employment'  \n",
    "# Statistic associated with industry:: Establishment Count,Average Weekly Wage,September Employment\n",
    "emp_dic = {}\n",
    "for i in industry:\n",
    "    tsearch = i\n",
    "    rook = search_industrydata_cleaner(collect,stat,tsearch)\n",
    "    emp_dic[i] = rook\n",
    "# Plot\n",
    "for i in industry:\n",
    "    plt.plot(years,emp_dic[i],label=i)\n",
    "    plt.suptitle('Number of Jobs in Largest Industries')\n",
    "    plt.ylabel('Number of People Employed')\n",
    "    plt.xlabel('Year')\n",
    "    plt.title(name)\n",
    "    plt.legend()\n",
    "plt.grid()\n",
    "#plt.savefig('Industries with most employed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call Wage Numbers\n",
    "stat = 'Average Weekly Wage'  \n",
    "# Statistic associated with industry:: Establishment Count,Average Weekly Wage,September Employment\n",
    "wage_dic = {}\n",
    "for i in industry:\n",
    "    tsearch = i\n",
    "    rook = search_industrydata_cleaner(collect,stat,tsearch)\n",
    "    wage_dic[i] = rook\n",
    "# Plot\n",
    "for i in industry:\n",
    "    plt.plot(years,wage_dic[i],label=i)\n",
    "    plt.suptitle('Average Weekly Wages per Industry')\n",
    "    plt.ylabel('Average Weekly Wages')\n",
    "    plt.xlabel('Year')\n",
    "    plt.title(name)\n",
    "    plt.legend()\n",
    "plt.grid()\n",
    "print(wage_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indus_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ind_vars = crime_dic['DRGPOSS']\n",
    "dep_vars = emp_dic['Service-providing'][:-1] \n",
    "# Number of establishments per service providing industry\n",
    "# Number of Drug Possesions in county\n",
    "\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(dep_vars, ind_vars).fit()\n",
    "predictions = model.predict(ind_vars) # make the predictions by the model\n",
    "\n",
    "# Print out the statistics\n",
    "print(model.summary())\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(years[:-1],crime_dic['DRGPOSS'],color='b',label='Number of Drug Posession Arrests')\n",
    "ax1.set_ylabel('Number of Drug Posession Arrests', color='b')\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2.plot(years[:-1],emp_dic['Service-providing'][:-1],color='r',label='Number of Service Industry Establishments')\n",
    "ax2.set_ylabel('Number Employed in Service Industry', color='r')\n",
    "plt.title(name)\n",
    "plt.grid()\n",
    "print(\"\\n Number of Jobs in the Service Industry plotted against number of drug posession arrests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wage_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Regression Testing\n",
    "multireg_dic = {}    \n",
    "for i in wage_dic:  # For each industry in the wage dictionary\n",
    "    multireg_dic[i+\" wages\"] = wage_dic[i][:-1] # Add wage data to new dictionary, retitle for calraification\n",
    "    multireg_dic[i+\" jobs\"] = emp_dic[i][:-1]  # Add employment numbers per industry, retitle for calarification\n",
    "# Now we have employment and wage data in a single dictionary    \n",
    "\n",
    "multireg = pd.DataFrame(data=multireg_dic)  # Convert dictionary into a dataframe\n",
    "x = multireg[list(multireg.columns.values)[:3]]  # Use only the first 3 columns to regress\n",
    "y = crime_dic['DUI']  # Set y variable\n",
    "\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x) # make the predictions by the model\n",
    "\n",
    "print('Crime Dictionary (y vars): ',crime_dic)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exog_vars = test\n",
    "# exog = sm.add_constant(test['Service-Wages'])\n",
    "# mod = RandomEffects(y,exog)\n",
    "# RE_res = mod.fit()\n",
    "# print(RE_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multireg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2)\n",
    "for i in industry:\n",
    "    ax[0].plot(years,wage_dic[i],label=i)\n",
    "    ax[1].plot(years,emp_dic[i],label=i)\n",
    "    ax[1].legend(loc='right')\n",
    "print(\"Top graph: Wages \\nBottom graph: Number of jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samp_db.keys())\n",
    "\n",
    "agg_crimes = []  # List of crime coutns for all counties in sample database\n",
    "for n in samp_db:  # For each county in sample\n",
    "    for i in crimes:  # For each crime in that county\n",
    "        tsearch = i\n",
    "        agg_crimes.append(searchcrime_cleaner(samp_db[n],crimes,tsearch))  # Pull data\n",
    "     \n",
    "# \n",
    "test_dic = {}\n",
    "# Create dictionary keys\n",
    "for n in industry:\n",
    "    test_dic[\"Wages \"+n] = ()\n",
    "    test_dic[\"Jobs \"+n] = ()\n",
    "# Pull and organize data into dictionary\n",
    "for i in samp_db:\n",
    "    for n in industry:\n",
    "        test_dic[\"Wages \"+n] = test_dic[\"Wages \"+n]+wage_dic[n][:-1]\n",
    "        test_dic[\"Jobs \"+n] = test_dic[\"Jobs \"+n]+emp_dic[n][:-1]\n",
    "print(\"Crimes\",crimes)\n",
    "print(\"            CNTY01 // DRGPOSS //             AGASSLT //            DUI\")\n",
    "print(\"Aggregate Crimes: \",agg_crimes)\n",
    "# print(\"Collect: \",collect['Crime'][0])\n",
    "\n",
    "# for i in test_dic:\n",
    "#     test_dic[i] = test_dic[i]+test_list\n",
    "print(test_dic.keys())\n",
    "print('\\n\\n\\n',test_dic)\n",
    "print(len(test_dic['Wages Service-providing']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_dic[\"Wages Service-providing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wage_dic = {}\n",
    "# for i in industry:\n",
    "#     tsearch = i\n",
    "#     rook = search_industrydata_cleaner(collect,stat,tsearch)\n",
    "#     wage_dic[i] = rook\n",
    "\n",
    "#     wage5 = wage18[0].loc[(wage18[0]['GU Name'] == county) & (wage18[0]['State Abbreviation'] == state)]\n",
    "industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_db['NM, Lincoln']['Crime'][0]  #['P1VLNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning data sample database\n",
    "def industrydata_cleaner(data,stat,tsearch):\n",
    "    container = []\n",
    "    for i in data:\n",
    "        for n in range(len(data[i]['Industry'])-1):  # -1 because only for years of crime data\n",
    "            x = data[i]['Industry'][n].loc[data[i]['Industry'][n]['Industry']== tsearch]\n",
    "            x = x[stat].values\n",
    "            #print(type(x))\n",
    "            container.append(x)\n",
    "    return container # Return a list of individual values\n",
    "def sample_crime_cleaner(data,crime):\n",
    "    container = []\n",
    "    for i in data:\n",
    "        for n in range(len(data[i]['Crime'])):\n",
    "            y = data[i]['Crime'][n][crime]\n",
    "            y = y.values\n",
    "            #print(type(y))\n",
    "            container.append(y[0])\n",
    "    return container\n",
    "\n",
    "test_dic = {}\n",
    "stat = 'Establishment Count'\n",
    "for n in industry:\n",
    "    test_dic[n] = industrydata_cleaner(samp_db,stat,n)\n",
    "    \n",
    "for i in crimes:\n",
    "    test_dic[i] = sample_crime_cleaner(samp_db,i)\n",
    "test = pd.DataFrame(data=test_dic)\n",
    "print(\"Sample Data: \",samp_db.keys(),'\\n')\n",
    "#print(\"Test Dictonary: \",test_dic.keys())\n",
    "\n",
    "plt.plot(test['Service-providing'])\n",
    "print('Average Weekly Wages')\n",
    "test\n",
    "# print(\"Crime db type: \",type(samp_db['NM, Lincoln']['Crime'][0]))\n",
    "# print(\"Industry db type: \",type(samp_db['NM, Lincoln']['Industry'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in test_dic['Education and health services']:\n",
    "    try:\n",
    "        print(j[0])\n",
    "    except:\n",
    "        print('')\n",
    "#     print(j[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serv_col = [i[0] for i in test_dic[\"Service-providing\"]]\n",
    "serv_colpd = pd.Series(serv_col)\n",
    "test['Service-providing'] = serv_colpd\n",
    "\n",
    "# Education and health services\n",
    "edu_list = np.array([])\n",
    "for i in test_dic[\"Education and health services\"]:\n",
    "    try:\n",
    "        edu_list = np.append(edu_list,i[0])\n",
    "    except:\n",
    "        edu_list = np.append(edu_list,0)\n",
    "edu_colpd = pd.Series(edu_list)\n",
    "test['Education and health services'] = edu_colpd\n",
    "\n",
    "# Professional and business services\n",
    "prof_list = np.array([])\n",
    "for i in test_dic[\"Professional and business services\"]:\n",
    "    try:\n",
    "        prof_list = np.append(prof_list,i[0])\n",
    "    except:\n",
    "        prof_list = np.append(prof_list,0)\n",
    "edu_colpd = pd.Series(prof_list)\n",
    "test['Professional and business services'] = edu_colpd\n",
    "\n",
    "trade_col = [i[0] for i in test_dic[\"Trade, transportation, and utilities\"]]\n",
    "trade_colpd = pd.Series(serv_col)\n",
    "test['Trade, transportation, and utilities'] = trade_colpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test[list(test.columns.values[:4])]  # Use only the first 3 columns to regress\n",
    "y = test['DUI']  # Set y variable\n",
    "\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x) # make the predictions by the model\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model23 = smf.ols(formula = 'y ~ x', data= test)\n",
    "f_lin_reg = model23.fit()\n",
    "f_lin_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samp_db.keys())\n",
    "# Pull desired crime and industry data\n",
    "base00 = {}\n",
    "for n in industry:  # Initializing keys\n",
    "    base00[n] = ()\n",
    "# while count > 5: # 5 for number of years available\n",
    "for i in samp_db:\n",
    "    for n in base00:\n",
    "        for z in range(len(samp_db[i]['Industry'])):\n",
    "            base00[n] = samp_db[i]['Industry'][z].loc[samp_db[i]['Industry'][z]['Industry'] == n]\n",
    "print(base00.keys())\n",
    "base00['Service-providing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
